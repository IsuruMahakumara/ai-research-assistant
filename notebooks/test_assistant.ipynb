{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AI Research Assistant - Testing Notebook\n",
        "\n",
        "This notebook provides interactive tests for the AI Research Assistant backend components.\n",
        "\n",
        "## Setup\n",
        "Make sure you have:\n",
        "1. Installed dependencies: `pip install -r requirements.txt`\n",
        "2. Set up your `.env` file with `HF_API_TOKEN`\n",
        "3. Added `jupyter` to your environment: `pip install jupyter`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add parent directory to path for imports\n",
        "import sys\n",
        "sys.path.insert(0, '..')\n",
        "\n",
        "# Load environment variables\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv('../.env')\n",
        "\n",
        "print(\"Environment loaded!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Test Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from app.config import get_settings\n",
        "\n",
        "settings = get_settings()\n",
        "print(f\"App Name: {settings.app_name}\")\n",
        "print(f\"LLM Model: {settings.hf_model_id}\")\n",
        "print(f\"Embedding Model: {settings.embedding_model}\")\n",
        "print(f\"Chunk Size: {settings.chunk_size}\")\n",
        "print(f\"HF Token Set: {'Yes' if settings.hf_api_token else 'No'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Test LLM Client\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from app.llm import HFInferenceClient\n",
        "\n",
        "llm_client = HFInferenceClient()\n",
        "print(f\"LLM Client initialized with model: {llm_client.model_id}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test text generation\n",
        "response = await llm_client.generate(\n",
        "    \"What is machine learning? Answer in one sentence.\",\n",
        "    max_new_tokens=100,\n",
        "    temperature=0.7\n",
        ")\n",
        "print(\"Generated response:\")\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test embeddings\n",
        "test_texts = [\"Hello world\", \"Machine learning is fascinating\"]\n",
        "embeddings = llm_client.get_embeddings(test_texts)\n",
        "print(f\"Generated {len(embeddings)} embeddings\")\n",
        "print(f\"Embedding dimension: {len(embeddings[0])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Test RAG Retriever\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from app.retriever import RAGRetriever\n",
        "\n",
        "retriever = RAGRetriever()\n",
        "print(\"RAG Retriever initialized\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ingest sample documents\n",
        "sample_docs = [\n",
        "    {\n",
        "        \"content\": \"\"\"\n",
        "        Transformers are a type of neural network architecture that has revolutionized \n",
        "        natural language processing. They use self-attention mechanisms to process \n",
        "        sequential data in parallel, unlike RNNs which process sequentially. \n",
        "        The transformer architecture was introduced in the paper 'Attention Is All You Need' \n",
        "        by Vaswani et al. in 2017. Key components include multi-head attention, \n",
        "        positional encodings, and feed-forward layers.\n",
        "        \"\"\",\n",
        "        \"source\": \"transformers_overview.txt\"\n",
        "    },\n",
        "    {\n",
        "        \"content\": \"\"\"\n",
        "        RAG (Retrieval-Augmented Generation) is a technique that combines information \n",
        "        retrieval with text generation. It retrieves relevant documents from a knowledge \n",
        "        base and uses them as context for generating responses. This helps reduce \n",
        "        hallucinations and grounds the model's outputs in factual information.\n",
        "        RAG systems typically use dense retrieval with embeddings and vector similarity search.\n",
        "        \"\"\",\n",
        "        \"source\": \"rag_explained.txt\"\n",
        "    },\n",
        "    {\n",
        "        \"content\": \"\"\"\n",
        "        Fine-tuning is the process of taking a pre-trained model and training it further \n",
        "        on a specific dataset for a particular task. This leverages the general knowledge \n",
        "        learned during pre-training while adapting the model to new domains or tasks.\n",
        "        Common fine-tuning approaches include full fine-tuning, LoRA, and prompt tuning.\n",
        "        \"\"\",\n",
        "        \"source\": \"fine_tuning_guide.txt\"\n",
        "    }\n",
        "]\n",
        "\n",
        "for doc in sample_docs:\n",
        "    doc_id, chunks = await retriever.ingest(doc[\"content\"], doc[\"source\"])\n",
        "    print(f\"Ingested '{doc['source']}': {chunks} chunks (ID: {doc_id[:8]}...)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test retrieval\n",
        "query = \"How do transformers work?\"\n",
        "results = await retriever.retrieve(query, top_k=3)\n",
        "\n",
        "print(f\"Query: {query}\\n\")\n",
        "print(f\"Found {len(results)} relevant documents:\\n\")\n",
        "for i, (doc, score) in enumerate(results, 1):\n",
        "    print(f\"{i}. Source: {doc.source} (Score: {score:.4f})\")\n",
        "    print(f\"   Content: {doc.content[:100]}...\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Test Research Planner\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from app.agents import ResearchPlanner\n",
        "\n",
        "planner = ResearchPlanner()\n",
        "\n",
        "# Test query decomposition\n",
        "complex_query = \"What are the main differences between transformers and RNNs, and when should I use each?\"\n",
        "plan = await planner.create_research_plan(complex_query)\n",
        "\n",
        "print(f\"Original Query: {plan['original_query']}\\n\")\n",
        "print(f\"Strategy: {plan['strategy']}\")\n",
        "print(f\"Estimated Steps: {plan['estimated_steps']}\\n\")\n",
        "print(\"Sub-questions:\")\n",
        "for i, sq in enumerate(plan['sub_questions'], 1):\n",
        "    print(f\"  {i}. {sq}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Test Reasoning Agent (Full Pipeline)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from app.agents import ReasoningAgent\n",
        "\n",
        "# Use the retriever we already populated with documents\n",
        "reasoning_agent = ReasoningAgent(retriever)\n",
        "print(\"Reasoning Agent initialized\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test single question answering\n",
        "question = \"What is RAG and why is it useful?\"\n",
        "answer, sources = await reasoning_agent.answer_single_question(question, max_sources=3)\n",
        "\n",
        "print(f\"Question: {question}\\n\")\n",
        "print(f\"Answer:\\n{answer}\\n\")\n",
        "print(f\"Sources used: {len(sources)}\")\n",
        "for s in sources:\n",
        "    print(f\"  - {s['source']} (relevance: {s['relevance_score']:.4f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test full multi-step reasoning\n",
        "complex_question = \"How can I improve my NLP model's performance using modern techniques?\"\n",
        "\n",
        "result = await reasoning_agent.reason_and_answer(\n",
        "    query=complex_question,\n",
        "    max_sources=5,\n",
        "    use_decomposition=True\n",
        ")\n",
        "\n",
        "print(f\"Question: {complex_question}\\n\")\n",
        "print(\"=\" * 50)\n",
        "print(\"REASONING STEPS:\")\n",
        "print(\"=\" * 50)\n",
        "for step in result['reasoning_steps']:\n",
        "    print(f\"  â†’ {step}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"FINAL ANSWER:\")\n",
        "print(\"=\" * 50)\n",
        "print(result['answer'])\n",
        "\n",
        "print(f\"\\nConfidence: {result['confidence']:.2%}\")\n",
        "print(f\"Sources used: {len(result['sources'])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
